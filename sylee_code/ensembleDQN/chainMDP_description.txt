
TEAM : 5
- HyeokJin Kwon
- Seongmin Lee
- Sungyoung Lee

Training Explanation:
- mode selection is included when making new agent()
    
    1) Training mode (1)
     * if you type 1, the agent starts to train from the beginning
        - After typing 1, you can initialize weights of the Keras Models randomly
        depending on the seed you enter (integer from 1 to 10)
        - Training goes on for 300 episodes for default     (converged at about 100)
    
    2) Evaluation mode (2)
     * if you type 2, the agent starts to load saved model, and it is evaluated based on the loaded model
        - Saved Model(folder) is attatched in the zip file
        - Since we used "os.getcwd()" command, the "model" folder and "chain_test.py", "agent_chainMDP.py"
        should exist in the same folder, and TAs should run test code in the directory of the chainMDP_test.py file



Very litte implementation in chain_test.py file:

***************************************
***************************************
from chain_mdp import ChainMDP
from agent_chainMDP import agent


# recieve 1 at rightmost stae and recieve small reward at leftmost state
env = ChainMDP(10)
s = env.reset()

""" Your agent"""
agent = agent()

#######################################
# === For training from beginning === #
if agent.mode == 1 : agent.train(env) #     <-- what's added
# =================================== #
#######################################

done = False
cum_reward = 0.0
# always move right left: 0, right: 1
action = 1
while not done:    
    action = agent.action(s)
    ns, reward, done, _ = env.step(action)
    cum_reward += reward
    s = ns
print(f"total reward: {cum_reward}")
***************************************
***************************************